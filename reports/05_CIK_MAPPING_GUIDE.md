# CIK Mapping Documentation

## Purpose and Context

The CIK mapping script serves as the critical bridge between your M&A deals data and the SEC EDGAR filing system. Every company that files documents with the SEC is assigned a Central Index Key, which is a unique numeric identifier that EDGAR uses to organize all filings for that company. Your deals data identifies target companies using stock ticker symbols like "AAPL" or "MSFT", but to retrieve 10-K filings from EDGAR, you need to know the CIK identifiers like "0000320193" or "0000789019". This script performs the translation from ticker symbols to CIK identifiers in a systematic, documented manner that integrates seamlessly with your refined pipeline.

## How the Script Works

The script follows a straightforward four-step process that mirrors the structure you have seen in your ingestion and restriction scripts. First, it loads your restricted deals dataset from the sample restriction step, verifying that all required columns exist and documenting how many deals have ticker symbols available for matching. Second, it downloads the SEC company tickers master file from the official SEC website, which is a JSON file containing the complete mapping of all registered companies to their ticker symbols and CIK identifiers. Third, it prepares the SEC mapping data by standardizing ticker symbols to uppercase and zero-padding CIK identifiers to the ten-digit format that EDGAR expects. Fourth, it performs a left join between your deals and the SEC mapping table, adding CIK identifiers to deals that match successfully while retaining unmatched deals with NA values for diagnostic purposes.

The key technical insight underlying this process is that ticker symbol matching must be case-insensitive and whitespace-tolerant because different data sources may format ticker symbols slightly differently. The script handles this by creating a standardized ticker column where all symbols are converted to uppercase and trimmed of leading or trailing whitespace before the join operation occurs. This standardization ensures that a ticker recorded as " aapl " in your deals data will successfully match against "AAPL" in the SEC mapping file despite the formatting differences.

## Understanding Match Success Rates

When you run this script on your current data, you should expect a match success rate in the range of 70 to 85 percent based on typical characteristics of M&A deals data. The match rate will not be 100 percent for several legitimate reasons that do not indicate problems with your data or the matching process. Some deals in your sample involve targets that were acquired or delisted before they appeared in the current SEC mapping file, which means their historical ticker symbols no longer exist in the contemporary mapping. Some deals involve foreign companies with tickers on non-US exchanges that are not included in the SEC database because those companies never filed with the SEC. Some deals may have ticker symbols that changed due to corporate events like rebranding or ticker swaps that occurred after the deal announcement date.

The script produces detailed diagnostics that break down unmatched deals into two categories so you can understand exactly what is happening. Deals categorized as "no_ticker" had missing or empty ticker symbols in your original data, which means the match failure occurred because there was no ticker available to look up rather than because the lookup itself failed. Deals categorized as "ticker_not_in_sec" had valid ticker symbols that simply do not appear in the current SEC mapping file, which typically indicates historical or foreign tickers as described above. By separating these two categories, you can assess whether the unmatched deals represent systematic gaps in your data coverage or simply the expected limitations of matching contemporary SEC data against historical M&A transactions.

## The Status Field for Downstream Filtering

The script creates a new column called `cik_match_status` that explicitly documents why each deal did or did not receive a CIK identifier. This status field serves multiple purposes in your pipeline. First, it provides transparency about the matching process so you can verify that the join logic worked as expected and identify any systematic patterns in match failures. Second, it enables downstream scripts to make informed decisions about how to handle unmatched deals, such as excluding them from filing retrieval attempts or flagging them for manual research. Third, it facilitates thesis documentation by giving you precise statistics about CIK match rates that you can report in your methodology chapter.

The three status values have clear meanings that map to different pipeline implications. A status of "matched" means the deal successfully received a CIK identifier and can proceed to filing retrieval in the next pipeline step. A status of "no_ticker" means the deal lacked a ticker symbol in the original data, which indicates a fundamental data limitation where the target company was either not publicly traded or the ticker information was not captured in your SDC export. A status of "ticker_not_in_sec" means a ticker was present but could not be matched to the current SEC mapping, which suggests either a historical ticker that predates current SEC records or a foreign ticker from a company that never filed with the SEC.

## Integration with Your Pipeline

This CIK mapping script fits into your pipeline sequence immediately after sample restriction and immediately before filing identification. The input comes from `deals_sample_restricted.rds`, which contains your 8,986 deals that passed all research design inclusion criteria. The output goes to `deals_with_cik.rds`, which adds the `target_cik`, `sec_company_name`, and `cik_match_status` columns while retaining all existing columns from the restricted sample. Downstream scripts that need to retrieve EDGAR filings will read this output file and can filter to only the deals where `cik_match_status == "matched"` to focus their efforts on deals where filing retrieval is actually possible.

The script follows all the conventions you have established in your pipeline including using RDS format for data files to preserve R data types, creating comprehensive logs with timestamps and status levels, producing machine-readable JSON summaries for programmatic access, and generating human-readable console output that shows key statistics. This consistency makes it easy to understand what each script in your pipeline does and ensures that all scripts produce comparable documentation suitable for your thesis methodology chapter.

## Expected Output on Your Current Data

When you run this script on your restricted sample of 8,986 deals, the exact match rate will depend on the characteristics of your Deals_v1 file, but you can anticipate certain patterns based on typical M&A data properties. Most of your deals should have ticker symbols available because your SDC export focused on publicly traded targets, which means the "no_ticker" category should be relatively small, perhaps 5 to 15 percent of deals. Among deals with tickers, the match rate to the SEC mapping should be reasonably high for recent deals but lower for deals from earlier in your time period because older tickers are more likely to have disappeared from the contemporary SEC file due to delistings or corporate changes.

If your match rate turns out to be substantially lower than 70 percent, that may indicate that your SDC export includes a significant proportion of non-US targets or deals from before a certain cutoff year when SEC filing practices were different. In that case, you may want to revisit the configuration of your sample restriction script to enable the US listing filter or the time period filter to ensure your final analytical sample focuses on deals where 10-K filing retrieval is feasible. The detailed diagnostics produced by this script will help you make that assessment by showing you examples of unmatched tickers and the breakdown of match failure reasons.

## Technical Notes on the SEC Mapping File

The SEC company tickers file is updated regularly as new companies register with the SEC and existing companies update their information. The script downloads the current version from the official SEC website each time it runs, which ensures you always have the most up-to-date mapping available. However, this also means that if you run the script multiple times across a span of months, you might see slight variations in match rates as the SEC file evolves. For reproducibility in your final analysis, you may want to download the SEC mapping file once and save it locally so that all subsequent runs use the same version rather than fetching a potentially updated version each time.

The script saves the processed SEC mapping to a CSV file at `data/interim/ticker_cik_lookup.csv` so you can manually inspect the mapping table if needed. This file provides a useful reference when you encounter an unmatched ticker and want to verify whether it truly does not exist in the SEC database or whether there might be a formatting issue preventing the match. You can open this CSV in Excel or any spreadsheet program and search for tickers to check their presence in the SEC mapping.

The CIK identifiers are zero-padded to exactly ten digits because that is the format EDGAR expects when constructing filing URLs and queries. The SEC assigns CIKs as simple integers like 320193, but EDGAR URLs use the zero-padded format like 0000320193. By standardizing to the zero-padded format during the matching step, we ensure that downstream scripts that construct EDGAR queries do not need to worry about padding logic and can simply use the CIK identifiers as they appear in the data.

## What Comes After CIK Mapping

Once you have CIK identifiers attached to your deals, the next pipeline step is filing identification, where you query EDGAR for each matched deal to determine which specific 10-K filing should be used for that deal following your research design timing rules. The filing identification script will need to retrieve filing metadata from EDGAR for each CIK, filter the list of filings to only 10-K forms, apply the timing criterion that requires the filing to predate the announcement date by at least your configured minimum lag, and select the most recent filing that meets these criteria. That script will add columns like `filing_date`, `filing_accession_number`, and `filing_url` to your dataset, creating a clean one-to-one mapping from each deal to the specific 10-K that should be used for NLP processing.

After filing identification comes text extraction, where you download each identified 10-K filing from EDGAR and parse it to extract the MD&A and Risk Factors sections. That step requires careful HTML parsing because EDGAR documents use complex formatting and section headers that vary across different filing years and different companies. Once you have clean extracted text for each section, you can proceed to NLP processing where you construct the disclosure quality indices that serve as your key explanatory variables in the econometric analysis.

## Running the Script

To execute the CIK mapping on your current restricted sample, simply run the script from your R console or from the command line. The script will automatically find your restricted deals file, download the current SEC mapping, perform the join, and save all outputs including the matched dataset, the detailed log, the summary statistics, and the lookup table. Watch the console output to see the match statistics in real time and verify that the results align with your expectations before proceeding to the next pipeline step.

If you encounter any errors during execution, the detailed log file will contain timestamped information about exactly where the failure occurred, whether it was during data loading, SEC API access, JSON parsing, or the join operation. The script includes error handling for common failure modes like network timeouts and API changes, but if you encounter an error that is not gracefully handled, the log should give you enough information to diagnose the problem and adjust the script if needed.
